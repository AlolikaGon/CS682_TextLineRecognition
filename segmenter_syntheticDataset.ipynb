{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jhelu\\miniconda3\\envs\\cs682\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\jhelu\\miniconda3\\envs\\cs682\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "c:\\users\\jhelu\\miniconda3\\envs\\cs682\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage import io, transform, util\n",
    "from scipy.signal import argrelextrema\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from operator import itemgetter\n",
    "from skimage.filters import threshold_mean\n",
    "\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "\n",
    "# from skgof import ks_test, cvm_test, ad_test\n",
    "from scipy.stats import ks_2samp, anderson_ksamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_segmentation_data import *\n",
    "transformed_dataset = SegmentaionDataset('./datasets/train_data_icdar2019/strings/',\n",
    "                                           transform=transforms.Compose([ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21876"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transformed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 33, 700]) torch.Size([1, 1, 700]) 10508\n",
      "1 torch.Size([1, 33, 700]) torch.Size([1, 1, 700]) 20690\n",
      "2 torch.Size([1, 33, 700]) torch.Size([1, 1, 700]) 7526\n",
      "3 torch.Size([1, 33, 700]) torch.Size([1, 1, 700]) 17687\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(transformed_dataset)):\n",
    "    sample = transformed_dataset[i]\n",
    "\n",
    "    print(i, sample['image'].size(), sample['landmark'].size(), sample['values'])\n",
    "\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "NUM_TRAIN = int(0.8 * len(transformed_dataset))\n",
    "NUM_VAL = int(0.9 * len(transformed_dataset))\n",
    "NUM_TEST = len(transformed_dataset)\n",
    "\n",
    "loader_train = DataLoader(transformed_dataset, batch_size=batch_size_train,\n",
    "                                           sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "loader_val = torch.utils.data.DataLoader(transformed_dataset, batch_size = batch_size_train, \n",
    "                                           sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, NUM_VAL)))\n",
    "\n",
    "loader_test = DataLoader(transformed_dataset,batch_size = NUM_TEST - NUM_VAL,\n",
    "                                          sampler=sampler.SubsetRandomSampler(range(NUM_VAL, NUM_TEST)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([2188, 1, 33, 700]) torch.Size([2188, 1, 1, 700])\n"
     ]
    }
   ],
   "source": [
    "# for i_batch, sample_batched in enumerate(loader_val):\n",
    "#     print(i_batch, sample_batched['image'].size(),sample_batched['landmark'].size())\n",
    "for i_batch, sample_batched in enumerate(loader_test):\n",
    "    print(i_batch, sample_batched['image'].size(),sample_batched['landmark'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_custom_euclidean(x, y):\n",
    "    return torch.mean(torch.sqrt(torch.sum(torch.square(x-y), dim=-1)))\n",
    "\n",
    "class CustomActivation_inverse_quadratic(nn.Module):\n",
    "    def __init__(self, epsilon=1):\n",
    "        super(CustomActivation_inverse_quadratic, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return 1/(1 + (self.epsilon*x)**2)\n",
    "    \n",
    "def check_accuracy_part34(loader, model):   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    total_loss = []\n",
    "#     orig_ks_loss = [[], []]\n",
    "#     ks_loss = [[], []]\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for t, x_y in enumerate(loader):\n",
    "            x = x_y['image']\n",
    "            y = x_y['landmark']\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.float32)\n",
    "            scores = model(x)\n",
    "#             loss = torch.dist(scores, y)\n",
    "#             total_loss.append(loss.item())\n",
    "\n",
    "#             loss = my_custom_euclidean(scores,y)\n",
    "            loss = F.mse_loss(scores,y)\n",
    "            total_loss.append(float(loss))\n",
    "#             scores_numpy = scores.detach().cpu().numpy()\n",
    "#             scores_numpy = scores_numpy.reshape((scores_numpy.shape[0], -1))\n",
    "#             y_numpy = y.detach().cpu().numpy()\n",
    "#             y_numpy = y_numpy.reshape((y_numpy.shape[0], -1))\n",
    "#             for i in range(len(scores_numpy)):\n",
    "#                 index_max = argrelextrema(scores_numpy[i], np.greater)[0]\n",
    "#                 score_proj  = np.zeros(y_numpy[i].shape)\n",
    "#                 score_proj[index_max] = 1\n",
    "#                 stat, pvalue = ks_2samp(score_proj, y_numpy[i])\n",
    "#                 ks_loss[0].append(stat)\n",
    "#                 ks_loss[1].append(pvalue)\n",
    "#                 stat, pvalue = ks_2samp(scores_numpy[i], y_numpy[i])\n",
    "#                 orig_ks_loss[0].append(stat)\n",
    "#                 orig_ks_loss[1].append(pvalue)\n",
    "    print('train/val loss = %.4f' % (np.mean(np.asarray(total_loss))))\n",
    "#     print('ks_test (stat pvalue) = %.4f, %.4f' %(np.mean(ks_loss[0]), np.mean(ks_loss[1])))\n",
    "#     print('orig ks_test (stat pvalue) = %.4f, %.4f' %(np.mean(orig_ks_loss[0]), np.mean(orig_ks_loss[1])))\n",
    "#     return np.mean(np.asarray(total_loss)), np.mean(ks_loss[0]), np.mean(ks_loss[1])\n",
    "    return np.mean(np.asarray(total_loss))\n",
    "        \n",
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    train_loss, train_ks1, train_ks2, val_loss, val_ks1, val_ks2 = [], [], [], [], [], []\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, x_y in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x_y['image']\n",
    "            y = x_y['landmark']\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.float32)\n",
    "\n",
    "            scores = model(x)\n",
    "            #print(scores.size())\n",
    "            #loss = F.cross_entropy(scores, y)\n",
    "#             loss = torch.dist(scores, y)\n",
    "\n",
    "#             loss = my_custom_euclidean(scores,y)\n",
    "            loss = F.mse_loss(scores,y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, train loss = %.4f' % (t, loss.item()))\n",
    "                print()\n",
    "            if t == 0:\n",
    "                print(\"epoch \", e)\n",
    "                l = check_accuracy_part34(loader_train, model)\n",
    "                train_loss.append(l)\n",
    "#                 train_ks1.append(ks1)\n",
    "#                 train_ks2.append(ks2)\n",
    "                print()\n",
    "                l = check_accuracy_part34(loader_val, model)\n",
    "                val_loss.append(l)\n",
    "#                 val_ks1.append(ks1)\n",
    "#                 val_ks2.append(ks2)\n",
    "                print()\n",
    "#                 print('Iteration %d, train loss = %.4f' % (t, val_loss.item()))\n",
    "\n",
    "        l = check_accuracy_part34(loader_val, model)\n",
    "#         val_loss.append(l)\n",
    "#         val_ks1.append(ks1)\n",
    "#         val_ks2.append(ks2)\n",
    "#         print()\n",
    "        scheduler.step(l)\n",
    "                \n",
    "    return train_loss, train_ks1, train_ks2, val_loss, val_ks1, val_ks2\n",
    "                \n",
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [[5,5], [5,5], [3,7], [5,5], [3,3], [5,5], [5,2], [5, 5], [5,3], [3,3]]\n",
    "stride = [[2,1], [1,2], [1,1], [1,1], [1,1], [1,2], [1,1], [1,2], [1,1], [1,1]]\n",
    "padding = [[0,0], [0,2], [0,3], [0,2], [0,1], [0,2], [0,0], [0,1], [0,1], [0,0]]\n",
    "\n",
    "filters = [[5,5], [5,5], [3,7], [5,5], [3,3], [5,5], [5,2], [5, 5], [5,3], [3,3]]\n",
    "stride = [[1,1], [1,2], [1,1], [1,1], [1,1], [1,2], [1,1], [1,2], [1,1], [1,1]]\n",
    "padding = [[2,0], [2,2], [1,3], [2,2], [1,1], [2,2], [2,0], [2,1], [2,1], [1,0]]\n",
    "\n",
    "filters = np.asarray(filters)\n",
    "padding = np.asarray(padding)\n",
    "stride = np.asarray(stride)\n",
    "\n",
    "filters_copy = filters.copy()\n",
    "padding_copy = padding.copy()\n",
    "stride_copy = stride.copy()\n",
    "\n",
    "filters[:, 0] = filters_copy[:, 1]\n",
    "filters[:, 1] = filters_copy[:, 0]\n",
    "padding[:, 0] = padding_copy[:, 1]\n",
    "padding[:, 1] = padding_copy[:, 0]\n",
    "stride[:, 0] = stride_copy[:, 1]\n",
    "stride[:, 1] = stride_copy[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 700.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input = [33, 700]\n",
    "for i in range(len(filters)):\n",
    "    input[0] = (input[0]+2*padding[i][0]-filters[i][0])/stride[i][0]+1\n",
    "    input[1] = (input[1]+2*padding[i][1]-filters[i][1])/stride[i][1]+1\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, train loss = 0.8595\n",
      "\n",
      "epoch  0\n",
      "train/val loss = 0.9454\n",
      "\n",
      "train/val loss = 0.9454\n",
      "\n",
      "Iteration 100, train loss = 0.0511\n",
      "\n",
      "Iteration 200, train loss = 0.0422\n",
      "\n",
      "train/val loss = 0.0413\n",
      "Iteration 0, train loss = 0.0403\n",
      "\n",
      "epoch  1\n",
      "train/val loss = 0.0412\n",
      "\n",
      "train/val loss = 0.0414\n",
      "\n",
      "Iteration 100, train loss = 0.0387\n",
      "\n",
      "Iteration 200, train loss = 0.0360\n",
      "\n",
      "train/val loss = 0.0380\n",
      "Iteration 0, train loss = 0.0368\n",
      "\n",
      "epoch  2\n",
      "train/val loss = 0.0377\n",
      "\n",
      "train/val loss = 0.0382\n",
      "\n",
      "Iteration 100, train loss = 0.0384\n",
      "\n",
      "Iteration 200, train loss = 0.0357\n",
      "\n",
      "train/val loss = 0.0370\n",
      "Iteration 0, train loss = 0.0389\n",
      "\n",
      "epoch  3\n",
      "train/val loss = 0.0367\n",
      "\n",
      "train/val loss = 0.0370\n",
      "\n",
      "Iteration 100, train loss = 0.0357\n",
      "\n",
      "Iteration 200, train loss = 0.0370\n",
      "\n",
      "train/val loss = 0.0364\n",
      "Iteration 0, train loss = 0.0368\n",
      "\n",
      "epoch  4\n",
      "train/val loss = 0.0361\n",
      "\n",
      "train/val loss = 0.0364\n",
      "\n",
      "Iteration 100, train loss = 0.0378\n",
      "\n",
      "Iteration 200, train loss = 0.0358\n",
      "\n",
      "train/val loss = 0.0362\n",
      "Iteration 0, train loss = 0.0359\n",
      "\n",
      "epoch  5\n",
      "train/val loss = 0.0357\n",
      "\n",
      "train/val loss = 0.0361\n",
      "\n",
      "Iteration 100, train loss = 0.0381\n",
      "\n",
      "Iteration 200, train loss = 0.0370\n",
      "\n",
      "train/val loss = 0.0359\n",
      "Iteration 0, train loss = 0.0365\n",
      "\n",
      "epoch  6\n",
      "train/val loss = 0.0355\n",
      "\n",
      "train/val loss = 0.0359\n",
      "\n",
      "Iteration 100, train loss = 0.0374\n",
      "\n",
      "Iteration 200, train loss = 0.0344\n",
      "\n",
      "train/val loss = 0.0357\n",
      "Iteration 0, train loss = 0.0366\n",
      "\n",
      "epoch  7\n",
      "train/val loss = 0.0353\n",
      "\n",
      "train/val loss = 0.0356\n",
      "\n",
      "Iteration 100, train loss = 0.0356\n",
      "\n",
      "Iteration 200, train loss = 0.0334\n",
      "\n",
      "train/val loss = 0.0355\n",
      "Iteration 0, train loss = 0.0351\n",
      "\n",
      "epoch  8\n",
      "train/val loss = 0.0351\n",
      "\n",
      "train/val loss = 0.0354\n",
      "\n",
      "Iteration 100, train loss = 0.0351\n",
      "\n",
      "Iteration 200, train loss = 0.0344\n",
      "\n",
      "train/val loss = 0.0355\n",
      "Iteration 0, train loss = 0.0356\n",
      "\n",
      "epoch  9\n",
      "train/val loss = 0.0354\n",
      "\n",
      "train/val loss = 0.0357\n",
      "\n",
      "Iteration 100, train loss = 0.0351\n",
      "\n",
      "Iteration 200, train loss = 0.0345\n",
      "\n",
      "train/val loss = 0.0351\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "    \n",
    "class CustomActivation(nn.Module):\n",
    "    def __init__(self, mean=0, std=1, _min=0.0, _max=1.0):\n",
    "        super(CustomActivation, self).__init__()\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.min = _min\n",
    "        self.max = _max\n",
    "        \n",
    "    def forward(self, x):\n",
    "        gauss = torch.exp((-(x - self.mean)**2)/(2*self.std**2))\n",
    "        return torch.clamp(gauss, min=self.min, max=self.max)\n",
    "    \n",
    "class CustomActivation_inverse_quadratic(nn.Module):\n",
    "    def __init__(self, epsilon=1):\n",
    "        super(CustomActivation_inverse_quadratic, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return 1/(1 + (self.epsilon*x)**2)\n",
    "    \n",
    "class CustomActivation_multiquadratic(nn.Module):\n",
    "    def __init__(self, epsilon=1):\n",
    "        super(CustomActivation_multiquadratic, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.sqrt(1 + (self.epsilon*x)**2)\n",
    "    \n",
    "class CustomActivation_inverse_multiquadratic(nn.Module):\n",
    "    def __init__(self, epsilon=1):\n",
    "        super(CustomActivation_inverse_multiquadratic, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return 1/torch.sqrt(1 + (self.epsilon*x)**2)\n",
    "    \n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=tuple(filters[0]), padding=tuple(padding[0]), stride= tuple(stride[0]), bias = True), #26x26 , stride=(2,1)\n",
    "    nn.BatchNorm2d(6),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(6, 6, kernel_size=tuple(filters[1]), padding=tuple(padding[1]), stride=tuple(stride[1]), bias = True), #26x26\n",
    "    nn.BatchNorm2d(6),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(6, 6, kernel_size=tuple(filters[2]), padding=tuple(padding[2]), stride=tuple(stride[2]), bias = True), #13x13\n",
    "    nn.BatchNorm2d(6),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(6, 6, kernel_size=tuple(filters[3]), padding=tuple(padding[3]), stride=tuple(stride[3]), bias = True), #13x13\n",
    "    nn.BatchNorm2d(6),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(6, 6, kernel_size=tuple(filters[4]), padding=tuple(padding[4]), stride=tuple(stride[4]), bias = True), #13x13\n",
    "    nn.BatchNorm2d(6),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(6, 6, kernel_size=tuple(filters[5]), padding=tuple(padding[5]), stride=tuple(stride[5]), bias = True), #7x7\n",
    "    nn.BatchNorm2d(6),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(6, 6, kernel_size=tuple(filters[6]), padding=tuple(padding[6]), stride=tuple(stride[6]), bias = True), #7x7\n",
    "    nn.BatchNorm2d(6),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(6, 6, kernel_size=tuple(filters[7]), padding=tuple(padding[7]), stride=tuple(stride[7]), bias = True), #7x7\n",
    "    nn.BatchNorm2d(6),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(6, 6, kernel_size=tuple(filters[8]), padding=tuple(padding[8]), stride=tuple(stride[8]), bias = True), #7x7\n",
    "    nn.BatchNorm2d(6),\n",
    "#     nn.Tanh(),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(6, 1, kernel_size=tuple(filters[9]), padding=tuple(padding[9]), stride=tuple(stride[9]), bias = True), #7x7\n",
    "#     nn.ReLU(),\n",
    "#     nn.Sigmoid(),\n",
    "#     nn.BatchNorm2d(1),\n",
    "#     CustomActivation(),\n",
    "#     CustomActivation_inverse_multiquadratic(),\n",
    "#     nn.ReLU()()\n",
    "    CustomActivation_inverse_quadratic()\n",
    ")\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True, weight_decay=0.001)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, threshold = 1e-2, patience=3, verbose=True)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, 5)\n",
    "\n",
    "train_loss, train_ks1, train_ks2, val_loss, val_ks1, val_ks2 = train_part34(model, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/val loss = 0.0346\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, \"segmenter/segmenter_inverse_quadratic_mse_relu_700.h5\")\n",
    "# model = torch.load(\"segmenter/segmenter_gaussian_mse_relu_700.h5\")\n",
    "# model.eval()\n",
    "test_loss = check_accuracy_part34(loader_test, model)\n",
    "# train_loss_list = [0.9328, 0.0532, 0.0387, 0.0367, 0.0360, 0.0356, 0.0353, 0.0351, 0.0349, 0.0348]\n",
    "# val_loss_list = [0.9323, 0.0534, 0.0377, 0.0368, 0.0360,  0.0356, 0.0356, 0.0352, 0.0350, 0.0350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(len(train_loss)), train_loss, label='train loss.')\n",
    "plt.plot(np.arange(len(val_loss)), val_loss, label='val loss.')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.suptitle('Training and Validation Loss - Euclidean Distance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(len(train_ks2)), train_ks1, c='r', label='train acc.')\n",
    "plt.plot(np.arange(len(val_ks2)), val_ks1, c='b', label='val acc.')\n",
    "plt.xticks([1,2,3,4,5])\n",
    "plt.ylabel('ks_test - statistic')\n",
    "plt.xlabel('Epochs')\n",
    "plt.suptitle('KS_test on training and validation set')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_plot = {}\n",
    "stat_plot['train_loss'] = train_loss\n",
    "stat_plot['val_loss'] = val_loss\n",
    "stat_plot['test_loss'] = test_loss\n",
    "with open('seg-plot/stat_plot_inverse_quadratic_700_mse_relu.json', 'w') as fp:\n",
    "    json.dump(stat_plot, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relu 0.0345735102891922\n",
      "Sigmoid 0.03459661826491356\n",
      "Gaussian 0.034294724464416504\n",
      "Inv. quadratic 0.034570541232824326\n",
      "Inv. multiquadratic 0.03710968792438507\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# names = ['stat_plot_inverse_multiquadratic_700', 'stat_plot_sigmoid_700', 'stat_plot_gaussian_700']\n",
    "# labels = ['inv. multiquadratic', 'sigmoid', 'gaussian']\n",
    "names = ['stat_plot_relu_700_mse_relu', 'stat_plot_sigmoid_700_mse_relu',\n",
    "          'stat_plot_gaussian_700_mse_relu',\n",
    "           'stat_plot_inverse_quadratic_700_mse_relu', 'stat_plot_inverse_multiquaratic_700_mse_relu']\n",
    "labels = ['Relu', 'Sigmoid', 'Gaussian', 'Inv. quadratic', 'Inv. multiquadratic'   ]\n",
    "\n",
    "plt.figure()\n",
    "l = 0\n",
    "for name in names:\n",
    "    with open('seg-plot/'+name+'.json', 'r') as fp:\n",
    "        stat = json.load(fp)\n",
    "    train_loss = stat['train_loss']\n",
    "    val_loss = stat['val_loss']\n",
    "    print(labels[l], stat['test_loss'])\n",
    "    plt.plot(np.arange(len(train_loss)), train_loss, label=labels[l] +'-train loss.')\n",
    "#     plt.plot(np.arange(len(val_loss)), val_loss,'-', label=labels[l] +'-val loss.')\n",
    "    l += 1\n",
    "plt.ylim(0, 0.12)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.suptitle('Training Loss - Mean Square Error')\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_file = open('char_list_dict.pkl', 'rb')\n",
    "char_list_dict = pickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as levenshtein_distance\n",
    "# model = torch.load(\"segmenter/segmenter_inverse_multiquadratic_distloss_800.h5\")\n",
    "# model.eval()\n",
    "\n",
    "# label map if case sensitive\n",
    "label_map = {'(': 0, ')': 1, ',': 2, '.' :3, '-': 4, '/': 5, '<': 6, ' ':7}\n",
    "for i in range(10):\n",
    "    label_map[chr(48+i)] = 8+i\n",
    "for i in range(26):\n",
    "    label_map[chr(65+i)] = 18+i\n",
    "for i in range(26):\n",
    "    label_map[chr(97+i)] = 44+i\n",
    "\n",
    "classifier = load_model(\"classifier/classifierpaper_synthetic.h5\")\n",
    "dist_list = []\n",
    "dist1_list = []\n",
    "len_list = []\n",
    "fd_min = 2\n",
    "fd_max = 56\n",
    "fd_mean = [32] #[18.18]\n",
    "# model = torch.load(\"segmenter/segmenter_inverse_multiquadratic_distloss_800.h5\")\n",
    "# model.eval()\n",
    "#predict cuts\n",
    "with torch.no_grad():\n",
    "    for t, x_y in enumerate(loader_test):\n",
    "        x = x_y['image']\n",
    "        y = x_y['landmark']\n",
    "        x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "        y = y.to(device=device, dtype=torch.float32)\n",
    "        char_val = x_y['values']\n",
    "        scores_test = model(x)\n",
    "batch_size, _, ht, wd = x.size()\n",
    "#convert to numpy\n",
    "scores_temp = scores_test.detach().cpu().numpy()\n",
    "scores_temp = scores_temp.reshape((batch_size, -1))\n",
    "\n",
    "images = x.detach().cpu().numpy()\n",
    "images = images.reshape((batch_size,ht,wd))\n",
    "#actual result\n",
    "scores_actual = y.detach().cpu().numpy()\n",
    "scores_actual = scores_actual.reshape((scores_actual.shape[0], -1))\n",
    "for i in range(batch_size):\n",
    "    image_example = images[i]\n",
    "    score_example = scores_temp[i]\n",
    "    \n",
    "    index_actual = np.where(scores_actual[i]==1)[0]\n",
    "    # print(np.sum(scores_actual[100]))\n",
    "    char_list = char_list_dict[int(char_val[i])]\n",
    "    char_str = ''\n",
    "    for c in char_list:\n",
    "#         if (c >= 'A' and c<='Z') or (c>='a' and c<='z') or (c>='0' and c<='9'):\n",
    "        char_str += c\n",
    "#     count_chars = len(char_list_dict[int(char_val[100])])\n",
    "#     print(index_actual)\n",
    "\n",
    "    #local maxima indices\n",
    "    index_P = argrelextrema(score_example, np.greater)[0] \n",
    "    index_P_01 = np.zeros(score_example.shape)\n",
    "    index_P_01[index_P] = 1\n",
    "\n",
    "\n",
    "    #dist between left and right index of cuts\n",
    "    #len(index_P)xlen(index_P)\n",
    "    dist = pairwise_distances(np.asarray(index_P).reshape(-1,1), metric='manhattan') \n",
    "    #index pairs such that width is betwwen fd-min and fd-max\n",
    "    l, r = np.where((dist>= fd_min) & (dist<=np.mean(fd_mean)))\n",
    "    #top m = img_width/mean_char_width choices\n",
    "    l_r = []\n",
    "#     print(len(l))\n",
    "    for j in range(len(l)):\n",
    "        if l[j] < r[j]:\n",
    "            try:\n",
    "                l_r.append([ index_P[int(l[j])], index_P[int(r[j])], \n",
    "                                     score_example[index_P[int(l[j])]] + score_example[index_P[int(r[j])]] ])\n",
    "            except TypeError:\n",
    "                print(\"AAH\", l[j], r[j], len(index_P), )\n",
    "#     print(len(l_r))\n",
    "    # l_r = l_r[l_r[:,2].argsort()] #sort according to P(l) +P(r)\n",
    "    l_r_sorted = sorted(l_r, key = itemgetter(2), reverse=True)\n",
    "\n",
    "    char_images = []\n",
    "    #top m choices\n",
    "    for i in range(len(l_r)): # #np.mean(fd_mean))):\n",
    "        if l_r[i] in l_r_sorted[0:int(800/np.mean(fd_mean))]:\n",
    "            img_crop = image_example[:, l_r[i][0]: l_r[i][1]]\n",
    "            thresh = threshold_mean(img_crop)\n",
    "            img_bin = img_crop > thresh\n",
    "    #         img_bin = img_bin.astype(int)\n",
    "    #         img_resize = np.ones((28,28))\n",
    "    #         img_resize[:,7:21] = resize(img_bin, (28, 14))\n",
    "            img_bin = resize(img_bin, (28,28))\n",
    "            char_images.append(img_bin)\n",
    "\n",
    "    #view images\n",
    "#     %matplotlib inline \n",
    "#     plt.imshow(image_example, cmap='gray')\n",
    "#     plt.show()\n",
    "#     fig, axes = plt.subplots(int(np.sqrt(len(char_images))), int(np.sqrt(len(char_images))), figsize=(20,20))\n",
    "#     for i,ax in enumerate(axes.flat):\n",
    "#         ax.imshow(char_images[i], cmap='gray')\n",
    "\n",
    "    # fd_min=10\n",
    "    # fd_max=30\n",
    "    \n",
    "\n",
    "    X_test = np.asarray(char_images)\n",
    "    X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "    class_probs = np.asarray(classifier.predict(X_test))\n",
    "    max_scores = np.max(class_probs, axis=1)\n",
    "    max_scores_index = np.argmax(class_probs, axis=1)\n",
    "    output_str = ''\n",
    "    for s in max_scores_index:\n",
    "#         if s in range(0,10):\n",
    "#             output_str += str(s)\n",
    "#         elif s in range(10, 37):\n",
    "#             output_str += chr(65 + (s-10))\n",
    "#         else:\n",
    "#             output_str += chr(97 + (s-36))\n",
    "        for k, v in label_map.items():\n",
    "            if v == s:\n",
    "                output_str.append(k)\n",
    "    print(output_str)\n",
    "    dist_list.append(levenshtein_distance(output_str, char_str))\n",
    "    dist1_list.append(levenshtein_distance(output_str, char_str) * len(char_str))\n",
    "    len_list.append(len(char_str))\n",
    "    # for i in range(len(l_r)):\n",
    "    #     l_r[i][2] /= 2\n",
    "    #     l_r[i][2] += max_scores[i]\n",
    "    #     l_r[i].append(output_str[i])\n",
    "    # l_r = sorted(l_r, key = (itemgetter(2), itemgetter(1)), reverse=True)\n",
    "    # i=1\n",
    "    # while i<len(l_r):\n",
    "    #     if l_r[i][0] == l_r[i-1][0]:\n",
    "    #         l_r.remove(l_r[i])\n",
    "    #     i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(dist1_list)/sum(len_list))\n",
    "print(np.mean(dist_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_images = []\n",
    "for i in range(1, len(index_actual)):\n",
    "    img_crop = image_example[:, index_actual[i-1]: index_actual[i]]\n",
    "    thresh = threshold_mean(img_crop)\n",
    "    img_bin = (img_crop > thresh)*1\n",
    "#     img_bin = img_bin.astype(int)\n",
    "#     img_resize = np.ones((28,28))\n",
    "#     img_resize[:,7:21] = img_bin.resize(28, 14)\n",
    "#     img_resize = util.invert(img_resize)\n",
    "    img_bin = resize(img_bin, (28,28))\n",
    "    org_images.append(img_bin)  \n",
    "    \n",
    "#view images\n",
    "%matplotlib inline \n",
    "fig, axes = plt.subplots(int(np.sqrt(len(org_images))), int(np.sqrt(len(org_images))), figsize=(20,20))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ax.imshow(org_images[i], cmap='gray')\n",
    "\n",
    "# fd_min=10\n",
    "# fd_max=30\n",
    "# classifier = load_model(\"classifier/classifier1_EnglishFNT.h5\")\n",
    "\n",
    "X_test = np.asarray(org_images)\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "class_probs = np.asarray(classifier.predict(X_test))\n",
    "max_scores = np.max(class_probs, axis=1)\n",
    "max_scores_index = np.argmax(class_probs, axis=1)\n",
    "output_str = ''\n",
    "for s in max_scores_index:\n",
    "    if s in range(0,10):\n",
    "        output_str += str(s)\n",
    "    elif s in range(10, 37):\n",
    "        output_str += chr(65 + (s-10))\n",
    "    else:\n",
    "        output_str += chr(97 + (s-36))\n",
    "print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fd_min=1\n",
    "fd_max=200\n",
    "classifier = load_model(\"classifier/classifier1_EnglishFNT.h5\")\n",
    "dp = np.zeros((int(800/fd_min), 800))\n",
    "for k in range(dp.shape[0]):\n",
    "    if k==0:\n",
    "        for x in range(fd_max):\n",
    "            dp[k, x] = 0.5 * score_example[x]\n",
    "    else:\n",
    "        candidate_characters = []\n",
    "        for x in range(dp.shape[1]):   \n",
    "            if x-fd_min >0 and dp[k-1, x-fd_min]!=0.0:\n",
    "                prev_cut = np.argmax(dp[k-1, max(0, x-fd_max): max(0, x-fd_min)])\n",
    "                dp[k, x] = 0.5*score_example[x] + dp[k-1, prev_cut]\n",
    "                candidate_characters.append(resize(image_example[:, prev_cut:x], (28,28)))\n",
    "        X_test=np.asarray(candidate_characters)\n",
    "        X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "        class_probs = np.asarray(classifier.predict(X_test))\n",
    "        max_classifier_scores = np.max(class_probs, axis=1)\n",
    "        max_score_index = np.argmax(class_probs, axis=1)\n",
    "        output_str = ''\n",
    "        for s in max_score_index:\n",
    "            if s in range(0,10):\n",
    "                output_str += str(s)\n",
    "            elif s in range(10, 37):\n",
    "                output_str += chr(65 + (s-10))\n",
    "            else:\n",
    "                output_str += chr(97 + (s-36))\n",
    "        print(k, output_str)\n",
    "        i=0\n",
    "        for x in range(dp.shape[1]):   \n",
    "            if x-fd_min >0:\n",
    "                dp[k,x] += max_classifier_scores[i]\n",
    "                i + 1\n",
    "    \n",
    "dp = [[np.argmax(score_example[0:fd_max]), 0.5*max(score_example[0:fd_max])]]\n",
    "for k in range(1, int(800/18.18)):\n",
    "    dp_temp = {}\n",
    "    candidate_characters = []\n",
    "    print(dp[k-1][0]+fd_min, dp[k-1][0]+fd_min+fd_max)\n",
    "    for x in range(dp[k-1][0]+fd_min, dp[k-1][0]+fd_min+fd_max+1):\n",
    "        dp_temp[x] = dp[k-1][1] + 0.5*score_example[x] \n",
    "        candidate_characters.append(resize(image_example[:, dp[k-1][0]:x], (28,28)))\n",
    "    X_test=np.asarray(candidate_characters)\n",
    "    X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "    class_probs = np.asarray(classifier.predict(X_test))\n",
    "    max_classifier_scores = np.max(class_probs, axis=1)\n",
    "    x = dp[k-1][0]+fd_min\n",
    "    for i in range(max_classifier_scores.shape[0]):\n",
    "        dp_temp[x] += max_classifier_scores[i]\n",
    "    x_new, val = max(dp_temp.items(), key=itemgetter(1))\n",
    "    dp.append([x_new, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(dp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dp, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import pairwise_distances\n",
    "# x = np.asarray([1,2,5,7]).reshape(-1, 1)\n",
    "# index = np.asarray(index).reshape(-1,1)\n",
    "# dist = pairwise_distances(index, metric='manhattan')\n",
    "# l, r = np.where((dist>= fd_min) & (dist<=fd_max))\n",
    "# l_r = []\n",
    "# for i in range(len(l)):\n",
    "#     if l[i]< r[i]:\n",
    "#         l_r.append([int(index[l[i]]), int(index[r[i]])])\n",
    "# print(index)\n",
    "# print(l_r)\n",
    "print(np.asarray(index).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(scores_actual)):\n",
    "    print(sum(scores_temp[i]), sum(scores_actual[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "index = 0\n",
    "ht = []\n",
    "wd = []\n",
    "fd_min = 10\n",
    "fd_max = 0\n",
    "fd_mean = []\n",
    "for d in os.listdir('./datasets/train_data_icdar2019/strings'):\n",
    "    if len(os.listdir('./datasets/train_data_icdar2019/strings/'+d+'/images')) != 0:\n",
    "        image_name_list = os.listdir('./datasets/train_data_icdar2019/strings/'+d+'/images')\n",
    "        #print(d, \"->\", len(image_name_list))\n",
    "\n",
    "        for img_name in image_name_list:\n",
    "            with open('./datasets/train_data_icdar2019/strings/'+d+'/markup/'+img_name+'.json', 'r') as fp:\n",
    "                label = json.load(fp)\n",
    "            image = io.imread('./datasets/train_data_icdar2019/strings/'+d+'/images/'+img_name)\n",
    "#             if index>5:\n",
    "#                 break\n",
    "            index += 1\n",
    "            for item in label:\n",
    "                #up, bottom, right, left = item['line_rect']\n",
    "                #img_crop = img.crop((left, up, right, bottom))\n",
    "                x, y, w, h = item['line_rect']\n",
    "#                 img_crop = img.crop((x, y, x+w, y+h))\n",
    "#                 fig = plt.figure()\n",
    "#                 img_crop = img_crop.resize((131, 33))\n",
    "#                 img_crop.show()\n",
    "#                 plt.imshow(img_crop,cmap='gray',interpolation='none')\n",
    "                if min(item['cuts_x'])< x or max(item['cuts_x'])>x+w:\n",
    "                    print('hai raam')\n",
    "                wd.append(w)\n",
    "                ht.append(h)\n",
    "                cuts = np.sort(np.asarray(item['cuts_x'])) * 800/image.shape[1]\n",
    "                cuts = cuts.astype('int')\n",
    "                cuts = np.unique(cuts)\n",
    "                fd = np.ediff1d(cuts)\n",
    "                if min(fd) == 0:\n",
    "                    print(cuts)\n",
    "                if fd_min> min(fd):\n",
    "                    fd_min = min(fd)\n",
    "                if fd_max<max(fd):\n",
    "                    fd_max = max(fd)\n",
    "                fd_mean.append(np.mean(fd))\n",
    "#                 val = [chr(x) for x in item['values']]\n",
    "#                 print(val)\n",
    "#                 print(img_crop.size, len(item['cuts_x']), len(item['let_blines']))\n",
    "print(min(ht), max(ht), len(ht))\n",
    "print(min(wd), max(wd), len(wd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fd_min, fd_max, np.mean(fd_mean))\n",
    "# a = np.asarray([1,4,7,23])\n",
    "# np.ediff1d(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.morphology import disk\n",
    "def segmentation(img):\n",
    "\n",
    "    #img=cv2.resize(img,None,fx=2,fy=2,interpolation=cv2.INTER_CUBIC)\n",
    "    r_c=img.shape\n",
    "    #print(r_c[0]) 185 max h \n",
    "    #print(r_c[1]) 653 max w\n",
    "    img_final=img\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #to grayscale\n",
    "    bnw_img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)[1] #to bnw\n",
    "    comp_img=cv2.bitwise_not(bnw_img) #complement\n",
    "    #mask = disk(2)\n",
    "    mask=cv2.getStructuringElement(cv2.MORPH_RECT,(3,3)) \n",
    "    objects = cv2.morphologyEx(comp_img, cv2.MORPH_OPEN, mask)\n",
    "    cv2.imwrite('objects.jpg',objects)\n",
    "    _, contours, hierarchy = cv2.findContours(objects, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    print(len(contours))\n",
    "    list_objects=[]\n",
    "    list_index=[]\n",
    "    index=1\n",
    "    for contour in contours:\n",
    "        # get rectangle bounding contour\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "        \"\"\"s=str(w)+' '+str(h)\n",
    "        print(s)\"\"\"\n",
    "        \"\"\"if w<10:\n",
    "            continue\"\"\"\n",
    "        if h<.27*r_c[0] or h>.8*r_c[0] or w<.035*r_c[1] or w>.1*r_c[1]: #64.75 148 22.85 65.3 \n",
    "            continue\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "        cropped = bnw_img[y :y +  h , x: x + w]\n",
    "        cropped_pad= cv2.copyMakeBorder(cropped,5,5,5,5,cv2.BORDER_CONSTANT,value=[255,255,255])\n",
    "        cropped_resize=cv2.resize(cropped_pad, (64,64))\n",
    "        s ='char' + str(index) + '.jpg' \n",
    "        cv2.imwrite(s , cropped_resize)\n",
    "        list_objects.append(s)\n",
    "        list_index.append(x)\n",
    "        index=index+1\n",
    "    list_objects=[x for _,x in sorted(zip(list_index, list_objects))]\n",
    "    cv2.imwrite('output.jpg',img)\n",
    "    return list_objects\n",
    "res = segmentation(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in os.listdir('./datasets/train_data_icdar2019/strings'):\n",
    "    if len(os.listdir('./datasets/train_data_icdar2019/strings/'+d+'/images')) != 0:\n",
    "        image_name_list = os.listdir('./datasets/train_data_icdar2019/strings/'+d+'/images')\n",
    "        #print(d, \"->\", len(image_name_list))\n",
    "\n",
    "        for img_name in image_name_list:\n",
    "            with open('./datasets/train_data_icdar2019/strings/'+d+'/markup/'+img_name+'.json', 'r') as fp:\n",
    "                label = json.load(fp)\n",
    "            image = io.imread('./datasets/train_data_icdar2019/strings/'+d+'/images/'+img_name)\n",
    "\n",
    "\n",
    "gray_img = cv2.cvtColor(image[50:90], cv2.COLOR_BGR2GRAY) #to grayscale\n",
    "bnw_img = cv2.threshold(gray_img, 127, 255, cv2.THRESH_BINARY)[1] #to bnw\n",
    "num_labels, labels_im = cv2.connectedComponents(bnw_img)\n",
    "_l = [] \n",
    "for i in range(num_labels):\n",
    "    r, c = np.where(labels_im == i)\n",
    "#     print(i, min(r), max(r), min(c), max(c))\n",
    "    _l.append([min(c), max(c)])\n",
    "_l = sorted(_l, key=itemgetter(0))\n",
    "\n",
    "index = 0\n",
    "fig, axes = plt.subplots(1, 10, figsize())\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if _l[index][1] - _l[index][0] <=200:\n",
    "        ax.imshow(line[:, _l[index][0]:_l[index][1], :] , cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(image[100:150])\n",
    "gray_img = cv2.cvtColor(image[100:150], cv2.COLOR_BGR2GRAY) #to grayscale\n",
    "bnw_img = cv2.threshold(gray_img, 127, 255, cv2.THRESH_BINARY)[1] #to bnw\n",
    "num_labels, labels_im = cv2.connectedComponents(bnw_img)\n",
    "_l = [] \n",
    "for i in range(num_labels):\n",
    "    r, c = np.where(labels_im == i)\n",
    "#     print(i, min(r), max(r), min(c), max(c))\n",
    "    _l.append([min(c), max(c)])\n",
    "_l = sorted(_l, key=itemgetter(0))\n",
    "print(_l)\n",
    "index = 0\n",
    "fig, axes = plt.subplots(1, 15, figsize=(30, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if _l[index][1] - _l[index][0] <=200:\n",
    "        ax.imshow(image[100:150, _l[index][0]:_l[index][1], :] , cmap='gray')\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[100:150].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_l = [] \n",
    "for i in range(num_labels):\n",
    "    r, c = np.where(labels_im == i)\n",
    "#     print(i, min(r), max(r), min(c), max(c))\n",
    "    _l.append([min(c), max(c)])\n",
    "_l = sorted(_l, key=itemgetter(0))\n",
    "\n",
    "index = 0\n",
    "fig, axes = plt.subplots(1, 10)\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if _l[index][1] - _l[index][0] <=200:\n",
    "        ax.imshow(line[:, _l[index][0]:_l[index][1], :] , cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
